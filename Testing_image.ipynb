{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ff13d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ashut\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ashut\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95210e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 359 files belonging to 36 classes.\n"
     ]
    }
   ],
   "source": [
    "test_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    r'C:\\Users\\ashut\\ML Notes\\6 Month internship AIT\\Fruit_Detection\\test',\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    image_size=(64, 64),\n",
    "    shuffle=True,\n",
    "    seed=None,\n",
    "    validation_split=None,\n",
    "    subset=None,\n",
    "    interpolation=\"bilinear\",\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb3968a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ashut\\anaconda3\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ashut\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cnn = tf.keras.models.load_model(r'C:\\Users\\ashut\\ML Notes\\6 Month internship AIT\\Fruit_Detection\\trained_model_tunned.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "625dd878",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "img=r'C:\\Users\\ashut\\ML Notes\\6 Month internship AIT\\Fruit_Detection\\test\\apple\\Image_1.jpg'\n",
    "# Reading an image in default mode\n",
    "# img = cv2.imread(image_path)\n",
    "# img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB) #Converting BGR to RGB\n",
    "# # Displaying the image \n",
    "# plt.imshow(img)\n",
    "# plt.title('Test Image')\n",
    "# plt.xticks([])\n",
    "# plt.yticks([])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "277a5f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 468ms/step\n"
     ]
    }
   ],
   "source": [
    "image = tf.keras.preprocessing.image.load_img(img,target_size=(64,64))\n",
    "input_arr = tf.keras.preprocessing.image.img_to_array(image)\n",
    "input_arr = np.array([input_arr])  # Convert single image to a batch.\n",
    "predictions = cnn.predict(input_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3406085e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.99999881e-01 2.54496507e-10 4.41588016e-10 2.35700782e-12\n",
      "  1.15489916e-10 6.78279100e-11 1.35112982e-12 1.06719883e-10\n",
      "  1.82926764e-12 1.97429529e-12 1.66713084e-12 9.84334467e-13\n",
      "  3.18348104e-13 1.67328110e-10 1.23664525e-11 1.01586795e-11\n",
      "  3.25782966e-14 7.43710757e-13 4.72804135e-14 2.75230394e-10\n",
      "  1.09413378e-09 1.88254283e-08 3.89037934e-12 8.18925017e-09\n",
      "  3.62051867e-15 2.95012015e-08 3.79671961e-10 1.23924415e-09\n",
      "  6.35665458e-08 6.43272069e-21 3.50202265e-17 2.44219114e-13\n",
      "  1.00484916e-14 4.19476519e-12 2.18444967e-12 3.07121203e-11]]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1933cd56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "result_index = np.argmax(predictions) #Return index of max element\n",
    "print(result_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "949818d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Displaying the image \n",
    "# plt.imshow(img)\n",
    "# plt.title('Test Image')\n",
    "# plt.xticks([])\n",
    "# plt.yticks([])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16eba7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's a apple\n"
     ]
    }
   ],
   "source": [
    "print(\"It's a {}\".format(test_set.class_names[result_index]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a7dceaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 64, 64, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 36), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb196b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set.save('test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89915289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apple',\n",
       " 'banana',\n",
       " 'beetroot',\n",
       " 'bell pepper',\n",
       " 'cabbage',\n",
       " 'capsicum',\n",
       " 'carrot',\n",
       " 'cauliflower',\n",
       " 'chilli pepper',\n",
       " 'corn',\n",
       " 'cucumber',\n",
       " 'eggplant',\n",
       " 'garlic',\n",
       " 'ginger',\n",
       " 'grapes',\n",
       " 'jalepeno',\n",
       " 'kiwi',\n",
       " 'lemon',\n",
       " 'lettuce',\n",
       " 'mango',\n",
       " 'onion',\n",
       " 'orange',\n",
       " 'paprika',\n",
       " 'pear',\n",
       " 'peas',\n",
       " 'pineapple',\n",
       " 'pomegranate',\n",
       " 'potato',\n",
       " 'raddish',\n",
       " 'soy beans',\n",
       " 'spinach',\n",
       " 'sweetcorn',\n",
       " 'sweetpotato',\n",
       " 'tomato',\n",
       " 'turnip',\n",
       " 'watermelon']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83daef0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img):\n",
    "    img = cv2.resize(img, (64, 64))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = img / 255.0  # Normalize pixel values\n",
    "    return img\n",
    "\n",
    "\n",
    "def real_time_fruit_recognition(frame):\n",
    "    # Preprocess frame for model prediction\n",
    "    image = tf.keras.preprocessing.image.load_img(image_path,target_size=(64,64))\n",
    "    input_arr = tf.keras.preprocessing.image.img_to_array(image)\n",
    "    input_arr = np.array([input_arr])  # Convert single image to a batch.\n",
    "    predictions = cnn.predict(input_arr)\n",
    "\n",
    "    # Predict class probabilities\n",
    "    predicted_class_idx = np.argmax(predictions)\n",
    "    predicted_class = test_set.class_names[predicted_class_idx]\n",
    "    confidence = predictions[0][predicted_class_idx]\n",
    "\n",
    "    print(predicted_class, confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15f65f8a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mreal_time_fruit_recognition\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36mreal_time_fruit_recognition\u001b[1;34m(frame)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreal_time_fruit_recognition\u001b[39m(frame):\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# Preprocess frame for model prediction\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m     image \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mpreprocessing\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mload_img(\u001b[43mimage_path\u001b[49m,target_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m64\u001b[39m,\u001b[38;5;241m64\u001b[39m))\n\u001b[0;32m     12\u001b[0m     input_arr \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mpreprocessing\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mimg_to_array(image)\n\u001b[0;32m     13\u001b[0m     input_arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([input_arr])  \u001b[38;5;66;03m# Convert single image to a batch.\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'image_path' is not defined"
     ]
    }
   ],
   "source": [
    "real_time_fruit_recognition(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd1d3d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "def classify(frame):\n",
    "    model_path = r'C:\\Users\\ashut\\ML Notes\\6 Month internship AIT\\Fruit_Detection\\trained_model_tunned.h5'\n",
    "    model = load_model(model_path)\n",
    "    frame = cv2.resize(frame, (64, 64))\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    frame = image.img_to_array(frame)\n",
    "    frame = frame / 255.0\n",
    "    frame = frame.reshape(64, 64,3)\n",
    "    frame = np.expand_dims(frame, axis=0)\n",
    "    predictions = model.predict(frame)\n",
    "    # predicted_class_idx = np.argmax(predictions)\n",
    "    # print(predicted_class_idx)\n",
    "    # predicted_class = classes[predicted_class_idx]\n",
    "\n",
    "    # confidence = predictions[0][predicted_class_idx]\n",
    "    return np.argmax(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41dd4a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_prediction(test_image):\n",
    "    model = tf.keras.models.load_model(\"trained_model_tunned.h5\")\n",
    "    image = tf.keras.preprocessing.image.load_img(test_image,target_size=(64,64))\n",
    "    input_arr = tf.keras.preprocessing.image.img_to_array(image)\n",
    "    input_arr = np.array([input_arr]) #convert single image to batch\n",
    "    predictions = model.predict(input_arr)\n",
    "    return np.argmax(predictions) #return index of max element\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5013b086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 111ms/step\n",
      "33\n",
      "['apple', 'banana', 'beetroot', 'bell pepper', 'cabbage', 'capsicum', 'carrot', 'cauliflower', 'chilli pepper', 'corn', 'cucumber', 'eggplant', 'garlic', 'ginger', 'grapes', 'jalepeno', 'kiwi', 'lemon', 'lettuce', 'mango', 'onion', 'orange', 'paprika', 'pear', 'peas', 'pineapple', 'pomegranate', 'potato', 'raddish', 'soy beans', 'spinach', 'sweetcorn', 'sweetpotato', 'tomato', 'turnip', 'watermelon']\n",
      "Model is Predicting it's a tomato\n"
     ]
    }
   ],
   "source": [
    "imgagessss=r\"C:\\Users\\ashut\\Downloads\\download (2).jpg\"\n",
    "imaze=r'C:\\Users\\ashut\\Downloads\\apple.jpg'\n",
    "\n",
    "from PIL import Image\n",
    "imga = Image.open(img)\n",
    "img_array = np.array(imga)\n",
    "result = model_prediction(imaze)\n",
    "with open(\"labels.txt\") as f:\n",
    "    content = f.readlines()\n",
    "    label = []\n",
    "    for i in content:\n",
    "        label.append(i[:-1])\n",
    "    print(result)    \n",
    "    print(label)    \n",
    "    print(\"Model is Predicting it's a {}\".format(label[result]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00b09864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "z='ludhiana'\n",
    "print(z[0:9:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6319490d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
